{
  "url": "https://docs.memfiredb.com/docs/app/development_guide/ai/ai/",
  "title": "总览 | MemFire Cloud在线文档",
  "depth": 1,
  "timestamp": "2025-08-12 17:36:51",
  "html": "<main class=\"page-content bg-transparent\">\n<div class=\"top-header d-print-none\" id=\"top-header\">\n<div class=\"header-bar d-flex justify-content-between\">\n<div class=\"d-flex align-items-center\">\n<a alt=\"HomePage\" aria-label=\"HomePage\" class=\"logo-icon me-3\" href=\"/\">\n<div class=\"small\">\n<!--?xml version=\"1.0\" encoding=\"UTF-8\"?-->\n<svg height=\"112px\" version=\"1.1\" viewbox=\"0 0 99 112\" width=\"99px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<title>MemFireDB备份 6</title>\n<defs>\n<lineargradient id=\"linearGradient-1\" x1=\"49.9999885%\" x2=\"49.9999885%\" y1=\"98.082503%\" y2=\"0.766550128%\">\n<stop offset=\"0%\" stop-color=\"#ED1C23\"></stop>\n<stop offset=\"100%\" stop-color=\"#FBAF3B\"></stop>\n</lineargradient>\n</defs>\n<g fill=\"none\" fill-rule=\"evenodd\" id=\"定稿\" stroke=\"none\" stroke-width=\"1\">\n<g id=\"MemFireDB备份-6\">\n<polygon fill=\"#F9AE7C\" id=\"Fill-1\" points=\"25.9728553 40.7912363 47.4268317 0.00591833831 1.15453123 26.7215251\"></polygon>\n<polygon fill=\"#F9AE7C\" id=\"Fill-3\" points=\"97.4213117 26.7267606 51.1285247 0.000910513587 72.4242993 40.8351686\"></polygon>\n<polygon fill=\"#F9904A\" id=\"Fill-5\" points=\"24.8347133 42.7618153 0.000455256793 28.682999 0.000455256793 82.1608764\"></polygon>\n<polygon fill=\"url(#linearGradient-1)\" id=\"Fill-7\" points=\"27.6634514 42.4662399 49.279044 109.05096 70.7296059 42.507213 49.2779058 1.3747617\"></polygon>\n<polygon fill=\"#F9904A\" id=\"Fill-9\" points=\"98.5660549 28.6951771 73.5622137 42.8047233 98.5660549 82.1719163\"></polygon>\n<polygon fill=\"#FB6D33\" id=\"Fill-13\" points=\"72.2987623 45.061545 50.7514582 111.900071 97.579172 84.8646465\"></polygon>\n<polygon fill=\"#FB6D33\" id=\"Fill-15\" points=\"26.1006687 45.0226206 0.987565799 84.8644188 47.8095888 111.898705\"></polygon>\n<path d=\"M60.0737516,38.507213 C59.3168872,35.669825 57.0462939,33.3514298 57.0462939,33.3514298 C57.0462939,33.3514298 57.0804382,35.8849338 56.2894295,37.513615 C55.4847631,39.1696116 53.8765685,40.3054773 53.8765685,40.3054773 C53.8765685,40.3054773 56.1016361,33.8840802 54.2715038,30.1247973 C52.0259496,25.5073552 49.1771803,23.3357803 49.1771803,23.3357803 C49.1771803,23.3357803 50.1070423,28.1319107 48.6240432,31.5065016 C47.1672215,34.8264618 42.8058614,36.7260208 40.7241997,38.7132167 C39.1865699,40.1791435 38.0814341,43.0711623 37.6068289,44.4847347 C37.5715465,44.5883056 37.560165,44.6918765 37.5533362,44.7943093 C37.584066,43.9816759 37.8890881,39.8024186 40.9654858,37.4293925 C43.8404325,35.2111538 41.2431925,30.3478731 41.2431925,30.3478731 C41.2431925,30.3478731 41.7212121,32.5638355 40.9939394,34.1401622 C40.2655285,35.7153507 38.7187936,36.5962726 38.0154218,38.259098 C37.3883056,39.7409589 37.5203301,44.1432921 37.5453692,44.8409731 C37.5453692,44.8591834 37.5476455,44.8762555 37.5476455,44.8921895 C37.5476455,44.9263338 37.5487836,44.9456822 37.5487836,44.9456822 L37.5487836,44.9115379 C37.5590269,45.2655001 37.7138142,45.6080808 37.9972116,45.8448143 L48.3713757,55.6442168 C48.8380139,56.0323232 49.5163466,56.0334614 49.9841229,55.6476312 L60.5938825,45.7105136 C60.9034571,45.4544316 61.0719021,45.0686015 61.0457249,44.6656992 C60.9546735,43.2282259 60.5699815,40.3692133 60.0737516,38.507213\" fill=\"#FFFFFF\" id=\"Fill-17\"></path>\n</g>\n</g>\n</svg>\n</div>\n<div class=\"big\">\n<svg height=\"20\" width=\"232\" xmlns=\"http://www.w3.org/2000/svg\"><defs><lineargradient id=\"a\" x1=\"50%\" x2=\"50%\" y1=\"98.083%\" y2=\".767%\"><stop offset=\"0%\" stop-color=\"#ED1C23\"></stop><stop offset=\"100%\" stop-color=\"#FBAF3B\"></stop></lineargradient></defs><g fill=\"none\" fill-rule=\"evenodd\"><path d=\"M78.622 12.384l1.596 21.94H77.49l-.847-14.154-8.98 15.523-4.899-15.53-4.416 14.162H55.6l7.085-21.871 5.712 17.174 10.224-17.244zm99.46.382l.324.01.454.036c.085.008.175.018.269.03l.61.096c1.09.203 2.518.644 3.883 1.596l.515.383-.46 3.694-.413-.62-.154-.195-.255-.285c-.765-.802-2.485-2.188-5.23-2.188-4.55 0-8.723 3.809-9.3 8.491-.287 2.311.334 4.469 1.755 6.077 1.342 1.517 3.257 2.354 5.39 2.354 2.606 0 4.58-1.225 5.606-2.04l.359-.3.424-.408.507-.552-.466 3.766-.093.06a12.622 12.622 0 01-4.577 1.842l-.629.1-.53.058-.418.027-.444.003c-2.918-.002-5.532-1.142-7.36-3.21-1.851-2.096-2.67-4.88-2.305-7.837.73-5.88 5.964-10.696 11.806-10.974l.732-.014zm18.174 9.018c1.724 0 3.344.713 4.443 1.956 1.101 1.248 1.59 2.88 1.377 4.596-.432 3.504-3.808 6.466-7.375 6.466-1.728 0-3.348-.715-4.45-1.96-1.096-1.242-1.583-2.864-1.377-4.563.44-3.52 3.818-6.495 7.382-6.495zm19.446.535l-1.486 12.02h-2.558l.16-1.292c-.936.93-2.462 1.755-4.173 1.755-1.318 0-2.48-.492-3.267-1.385-.804-.91-1.168-2.184-1.008-3.497l.9-7.274 2.597-.327-.914 7.402c-.101.785.084 1.466.525 1.968.49.552 1.27.845 2.25.845 1.526 0 3.3-1.155 3.51-2.873l.87-7.015 2.594-.327zm-63.587-.547c1.77 0 3.21.58 4.164 1.678 1.047 1.207 1.48 3.01 1.263 5.233l-.097.771h-9.914c.16 1.896 1.567 2.979 3.895 2.979 1.806 0 2.878-.434 3.868-.961l1.119-.623-.312 2.522-.106.06c-1.224.687-2.604 1.356-4.8 1.356-2.092 0-3.873-.708-5.006-1.992-.991-1.12-1.404-2.599-1.198-4.272.548-4.433 4.001-6.751 7.124-6.751zm-62.717 0c1.771 0 3.211.58 4.164 1.678 1.048 1.207 1.48 3.01 1.263 5.233l-.097.771h-9.914c.16 1.896 1.567 2.979 3.895 2.979 1.622 0 2.652-.35 3.563-.803l.594-.315.83-.466-.312 2.522-.105.06c-1.224.687-2.604 1.356-4.8 1.356-2.093 0-3.874-.708-5.007-1.992-.99-1.12-1.404-2.599-1.197-4.272.547-4.433 4-6.751 7.123-6.751zM231.476 12l-2.767 22.34h-2.556l.197-1.59c-1.104 1.191-2.882 2.021-4.471 2.021-1.781 0-3.24-.583-4.217-1.69-1.02-1.151-1.452-2.817-1.222-4.686.485-3.908 3.43-6.636 7.167-6.636 1.565 0 3.065.832 3.852 2.064l1.356-10.968 2.661-.855zm-42.07.002L186.64 34.34h-2.556l2.664-21.483 2.66-.854zm-56.632 1.268l-1.166 2.527h-9.586l-.85 6.867h6.627v.48h-.12l-.883 1.778v.24h-5.933l-1.138 9.163h-2.729l2.612-21.055h13.166zm2.715 9.038l-1.497 12.017h-2.559l1.455-11.722 2.601-.295zm-24.427-.537c1 0 1.93.427 2.616 1.204.84.95 1.224 2.29 1.053 3.677l-.955 7.673h-2.527l.922-7.445c.13-1.017-.027-1.81-.45-2.287-.326-.367-.815-.554-1.458-.554-1.954 0-3.178 1.346-3.332 2.613l-.955 7.673h-2.556l.922-7.445c.127-1.03-.024-1.826-.442-2.297-.319-.362-.801-.544-1.437-.544-1.522 0-3.3 1.166-3.516 2.901l-.912 7.385h-2.559l1.455-11.722 2.594-.295-.146 1.164c1.027-1.077 2.419-1.701 3.854-1.701 1.375 0 2.58.79 3.226 2.083.914-1.13 2.05-2.083 4.603-2.083zm29.487.532l-.206 1.73c1.082-.978 2.932-1.7 4.514-1.7h.269l-.271 2.282h-.214c-1.814 0-4.469.837-4.7 2.7l-.866 7.01h-2.558l1.45-11.693 2.582-.329zm55.47 1.865c-2.31 0-4.27 1.792-4.563 4.168-.144 1.145.15 2.196.824 2.957.64.725 1.586 1.126 2.656 1.126 2.292 0 4.241-1.78 4.532-4.14.146-1.169-.144-2.237-.821-3.003-.634-.715-1.567-1.108-2.628-1.108zm27.497-.029c-2.278 0-4.15 1.752-4.45 4.17-.149 1.187.137 2.255.8 3.006.611.692 1.526 1.076 2.57 1.076 2.294 0 4.173-1.743 4.468-4.143.152-1.21-.13-2.285-.79-3.033-.623-.704-1.52-1.076-2.598-1.076zm-134.356.045c-1.89 0-3.372 1.094-4.015 2.947h7.164a2.853 2.853 0 00-.71-1.956c-.574-.648-1.416-.991-2.439-.991zm62.715 0c-1.892 0-3.37 1.094-4.013 2.947h7.166a2.867 2.867 0 00-.713-1.956c-.573-.648-1.416-.991-2.44-.991zm-17.267-7.614c.919 0 1.706.748 1.754 1.668a1.587 1.587 0 01-1.603 1.692c-.917 0-1.704-.75-1.754-1.668a1.593 1.593 0 011.603-1.692z\" fill=\"#116\"></path><path d=\"M11.131 17.482L20.326.002.495 11.453zm30.621-6.028L21.912 0l9.127 17.5z\" fill=\"#F9AE7C\"></path><path d=\"M10.643 18.326L0 12.293v22.919z\" fill=\"#F9904A\"></path><path d=\"M11.856 18.2l9.264 28.536 9.193-28.519L21.119.59z\" fill=\"url(#a)\"></path><path d=\"M42.243 12.298l-10.716 6.047 10.716 16.872z\" fill=\"#F9904A\"></path><path d=\"M30.985 19.312l-9.234 28.645L41.82 36.371zm-19.799-.017L.423 36.37 20.49 47.957z\" fill=\"#FB6D33\"></path><path d=\"M25.746 16.503c-.324-1.216-1.298-2.21-1.298-2.21s.015 1.086-.324 1.784c-.345.71-1.034 1.197-1.034 1.197s.954-2.752.17-4.363c-.963-1.98-2.184-2.91-2.184-2.91s.398 2.056-.237 3.502c-.624 1.423-2.494 2.237-3.386 3.088-.659.629-1.132 1.868-1.336 2.474a.509.509 0 00-.023.133c.013-.349.144-2.14 1.463-3.157 1.232-.95.119-3.035.119-3.035s.205.95-.107 1.625c-.312.676-.975 1.053-1.277 1.766-.268.635-.212 2.522-.201 2.82v.023l.001.022v-.014a.54.54 0 00.193.4l4.446 4.2c.2.166.49.166.69.001l4.548-4.259a.535.535 0 00.193-.448c-.039-.616-.203-1.84-.416-2.639\" fill=\"#FFF\"></path></g></svg>\n</div>\n</a>\n<button class=\"btn btn-icon btn-soft\" id=\"close-sidebar\">\n<span class=\"material-icons size-20 menu-icon align-middle\">menu</span>\n</button>\n</div>\n<div class=\"d-flex align-items-center\">\n<ul class=\"list-unstyled mb-0\">\n</ul>\n<a class=\"btn btn-icon btn-default ms-4\" href=\"https://memfiredb.com/\" target=\"_blank\" type=\"button\">官网</a>\n<a class=\"btn btn-icon btn-default ms-4\" href=\"https://community.memfiredb.com/\" target=\"_blank\" type=\"button\">论坛</a>\n<a class=\"btn btn-icon btn-default ms-4\" href=\"https://cloud.memfiredb.com/auth/login\" target=\"_blank\" type=\"button\">登录</a>\n<button aria-label=\"Toggle user interface mode\" class=\"btn btn-icon btn-default ms-2\" id=\"mode\" type=\"button\">\n<span class=\"toggle-dark\">\n<svg fill=\"currentColor\" height=\"30\" viewbox=\"0 0 48 48\" width=\"30\" xmlns=\"http://www.w3.org/2000/svg\">\n<title>Enable dark mode</title>\n<path d=\"M24 42q-7.5 0-12.75-5.25T6 24q0-7.5 5.25-12.75T24 6q.4 0 .85.025.45.025 1.15.075-1.8 1.6-2.8 3.95-1 2.35-1 4.95 0 4.5 3.15 7.65Q28.5 25.8 33 25.8q2.6 0 4.95-.925T41.9 22.3q.05.6.075.975Q42 23.65 42 24q0 7.5-5.25 12.75T24 42Zm0-3q5.45 0 9.5-3.375t5.05-7.925q-1.25.55-2.675.825Q34.45 28.8 33 28.8q-5.75 0-9.775-4.025T19.2 15q0-1.2.25-2.575.25-1.375.9-3.125-4.9 1.35-8.125 5.475Q9 18.9 9 24q0 6.25 4.375 10.625T24 39Zm-.2-14.85Z\"></path>\n</svg>\n</span>\n<span class=\"toggle-light\">\n<svg fill=\"currentColor\" height=\"30\" viewbox=\"0 0 48 48\" width=\"30\" xmlns=\"http://www.w3.org/2000/svg\">\n<title>Enable light mode</title>\n<path d=\"M24 31q2.9 0 4.95-2.05Q31 26.9 31 24q0-2.9-2.05-4.95Q26.9 17 24 17q-2.9 0-4.95 2.05Q17 21.1 17 24q0 2.9 2.05 4.95Q21.1 31 24 31Zm0 3q-4.15 0-7.075-2.925T14 24q0-4.15 2.925-7.075T24 14q4.15 0 7.075 2.925T34 24q0 4.15-2.925 7.075T24 34ZM3.5 25.5q-.65 0-1.075-.425Q2 24.65 2 24q0-.65.425-1.075Q2.85 22.5 3.5 22.5h5q.65 0 1.075.425Q10 23.35 10 24q0 .65-.425 1.075-.425.425-1.075.425Zm36 0q-.65 0-1.075-.425Q38 24.65 38 24q0-.65.425-1.075.425-.425 1.075-.425h5q.65 0 1.075.425Q46 23.35 46 24q0 .65-.425 1.075-.425.425-1.075.425ZM24 10q-.65 0-1.075-.425Q22.5 9.15 22.5 8.5v-5q0-.65.425-1.075Q23.35 2 24 2q.65 0 1.075.425.425.425.425 1.075v5q0 .65-.425 1.075Q24.65 10 24 10Zm0 36q-.65 0-1.075-.425-.425-.425-.425-1.075v-5q0-.65.425-1.075Q23.35 38 24 38q.65 0 1.075.425.425.425.425 1.075v5q0 .65-.425 1.075Q24.65 46 24 46ZM12 14.1l-2.85-2.8q-.45-.45-.425-1.075.025-.625.425-1.075.45-.45 1.075-.45t1.075.45L14.1 12q.4.45.4 1.05 0 .6-.4 1-.4.45-1.025.45-.625 0-1.075-.4Zm24.7 24.75L33.9 36q-.4-.45-.4-1.075t.45-1.025q.4-.45 1-.45t1.05.45l2.85 2.8q.45.45.425 1.075-.025.625-.425 1.075-.45.45-1.075.45t-1.075-.45ZM33.9 14.1q-.45-.45-.45-1.05 0-.6.45-1.05l2.8-2.85q.45-.45 1.075-.425.625.025 1.075.425.45.45.45 1.075t-.45 1.075L36 14.1q-.4.4-1.025.4-.625 0-1.075-.4ZM9.15 38.85q-.45-.45-.45-1.075t.45-1.075L12 33.9q.45-.45 1.05-.45.6 0 1.05.45.45.45.45 1.05 0 .6-.45 1.05l-2.8 2.85q-.45.45-1.075.425-.625-.025-1.075-.425ZM24 24Z\"></path>\n</svg>\n</span>\n</button>\n</div>\n</div>\n</div>\n<div class=\"container-fluid\">\n<div class=\"layout-spacing\">\n<div class=\"d-md-flex justify-content-between align-items-center\"></div>\n<div class=\"row flex-xl-nowrap\">\n<div class=\"docs-toc col-xl-3 d-xl-block\"><toc>\n<div class=\"fw-bold text-uppercase mb-2\">本页</div>\n\n</toc></div>\n<div class=\"docs-toc-mobile d-print-none d-xl-none\">\n<button aria-expanded=\"false\" class=\"btn-secondary dropdown-toggle\" data-bs-offset=\"0,0\" data-bs-toggle=\"dropdown\" id=\"toc-dropdown-btn\" type=\"button\">背景</button>\n</div>\n<div class=\"docs-content col-12 col-xl-9 mt-0\">\n<div class=\"mb-0 d-flex\">\n<h1 class=\"content-title mb-0\">\n                                                    总览\n                                                    \n                                                </h1>\n</div>\n<div class=\"main-content\" data-bs-root-margin=\"0px 0px -65%\" data-bs-spy=\"scroll\" data-bs-target=\"#toc-mobile\" id=\"content\">\n<div data-prismjs-copy=\"\" data-prismjs-copy-error=\"\" data-prismjs-copy-success=\"\">\n<p>随着ChatGPT的爆火，人们逐渐认识到大语言模型（LLM）和生成式人工智能在多个领域具有潜力，如文稿撰写、图像生成、代码优化和信息搜索等。LLM已成为个人和企业的有力助手，引领着新的生态系统。本文将介绍Embedding相关概念以及构建由LLM驱动的专属AI对话机器人总体流程。</p>\n<h2 id=\"背景\">背景 <a aria-hidden=\"true\" class=\"anchor\" href=\"#%e8%83%8c%e6%99%af\"><i class=\"material-icons align-middle\">link</i></a></h2><p>AI领域技术不断突破，越来越多的企业和个人积极探索利用大型语言模型（LLM）和生成式人工智能技术，来构建专注于特定领域的具备人工智能能力的产品。目前大型语言模型在解决通用问题方面表现出色，但由于受到训练数据和模型规模的限制，其在专业知识和时效性方面存在一定局限性。例如ChatGPT的训练的数据都是2021年及以前的，这也意味着想要咨询2021年以后的知识ChatGPT并不能给出准确的回答。</p>\n<p>在信息时代，企业的知识库更新速度不断加快。因此，对于企业而言，如果希望在大型语言模型的基础上构建特定垂直领域的人工智能产品，就需要将自身的知识库输入到大型语言模型中进行训练。但是要知道，一个大语言模型的参数动辄上百数千亿。单单本地的一点知识库放进去就是沧海一粟。很难达到想要的效果。加之对硬条件要求过高，很少企业和个人有条件能够直接“投喂”到模型里面训练。</p>\n<p>目前有两种常见的方法实现：</p>\n<ul>\n<li>微调（Fine-tuning）：通过提供新的数据集对已有模型的权重进行微调，不断更新输入以调整输出，以达到所需的结果。这适用于数据集规模不大或针对特定类型任务或风格进行训练。</li>\n<li>提示调整（Prompt-tuning）：通过调整输入提示而非修改模型权重，从而实现调整输出的目的。相较于微调，提示调整具有较低的计算成本，需要的资源和训练时间也较少，同时更加灵活。\n但随着语言模型越来越大，Fine-tune的成本也越来越高。目前市面上已经涌现许多由大语言模型驱动的专属AI对话机器人，这些大都是通过提示调整来实现建立本地化AI知识库。</li>\n</ul>\n<h2 id=\"实现原理\">实现原理 <a aria-hidden=\"true\" class=\"anchor\" href=\"#%e5%ae%9e%e7%8e%b0%e5%8e%9f%e7%90%86\"><i class=\"material-icons align-middle\">link</i></a></h2><p>本文将展示开发一款专属AI对话机器人的流程：</p>\n<p><strong>第一阶段：数据准备</strong></p>\n<ol>\n<li>知识库信息提取和分块：从领域知识库中提取相关的文本信息，并将其分块处理。这可以包括将长文本拆分为段落或句子，提取关键词或实体等。这样可以将知识库的内容更好地组织和管理。</li>\n<li>调用大语言模型接口生成Embedding：利用大语言模型（如OpenAI）提供的接口，将分块的文本信息输入到模型中，并生成相应的文本Embedding。这些Embedding将捕捉文本的语义和语境信息，为后续的搜索和匹配提供基础。</li>\n<li>存储Embedding信息：将生成的文本Embedding信息、文本分块以及文本关联的metadata信息存入MemFireCloud PostgreSQL数据库中。</li>\n</ol>\n<p><strong>第二阶段：问答</strong></p>\n<ol>\n<li>用户提问。</li>\n<li>通过OpenAI提供的Embedding接口创建该问题的Embedding。通俗的说就是你发出的提问内容A，通过OpenAI的接口，返回问题内容A的一个向量，也就是我们之前说的Embedding。</li>\n<li>因为在步骤1我们已经将我们的本地的知识库进行分片和Embedding，我们现在只需要将A的Embedding值和我们知识库分片的Embedding值进行比对，通过pgvector这个扩展，能够帮我们过滤出PostgreSQL数据库中相似度大于一定阈值的文档块.</li>\n<li>然后将我们的提问内容A和过滤出来的文档块，作为prompt一同发送给OpenAI，并将OpenAI结果返回给用户。这样一来，用户得到的就是逻辑严谨准确率高且符合人类语法的回答。</li>\n</ol>\n<p>流程图如下：\n<img src=\"../../../img/ai/流程图.png\"/></p>\n<h2 id=\"关于产品\">关于产品 <a aria-hidden=\"true\" class=\"anchor\" href=\"#%e5%85%b3%e4%ba%8e%e4%ba%a7%e5%93%81\"><i class=\"material-icons align-middle\">link</i></a></h2><p>MemFire Cloud提供了一个开源工具包，用于使用Postgres和pgvector开发人工智能应用程序。使用MemFire Cloud客户端库，在规模上存储、索引和查询你的Embedding。\n这个工具包含以下功能：</p>\n<ul>\n<li>使用 Postgres 与 pgvector 来实现 向量存储 和嵌入支持。</li>\n<li>提供 Python客户端 ，用于管理非结构化嵌入。</li>\n<li>提供 数据库迁移 ，用于管理结构化嵌入。</li>\n<li>支持与多个流行的 AI 供应商 (如 OpenAI 、 Hugging Face 、LangChain 等) 进行集成。</li>\n</ul>\n<h2 id=\"相关概念--embedding\">相关概念 | Embedding <a aria-hidden=\"true\" class=\"anchor\" href=\"#%e7%9b%b8%e5%85%b3%e6%a6%82%e5%bf%b5--embedding\"><i class=\"material-icons align-middle\">link</i></a></h2><p>当谈到\"Embedding\"时，它通常是指将高维数据转换为低维表示的过程。在自然语言处理（NLP）和机器学习领域，“Embedding\"通常用来将单词、短语、文本或者图像数据转换为向量（也称为嵌入向量或词嵌入）。因为计算机是擅长处理数字运算的，所以将无法计算的文本数据转化为向量数据，从而便于后面的计算。\n你可能会疑问这些文本数据是如何转换成向量的，这又是如何规定的。接下来我将会为您讲解。</p>\n<p>我们描述一个人可以有很多形容词，假定我们有4个人（张三、李四、王五、赵六），给每个人都从“可爱的”、“高挑的”、“高智商的”、“善解人意的”、“多愁善感的”这5个方面进行描述。符合定义为1，不符合定义为0，那么这4个人的描述可能是：</p>\n<div class=\"prism-codeblock\">\n<div class=\"code-toolbar\"><pre class=\"language-python\" id=\"6bd71b1\" tabindex=\"0\"><code class=\"language-python\"><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></code></pre><div class=\"toolbar\"><div class=\"toolbar-item\"><button aria-label=\"copy\" class=\"copy-to-clipboard-button\" data-copy-state=\"copy\" type=\"button\"><span></span></button></div></div></div>\n</div>\n<p>每个向量都有5个维度，每个维度都代表一个方面的描述。从左到右的依次表示为：“可爱的”、“高挑的”、“高智商的”、“善解人意的”、“多愁善感的”。向量1-4分别代表：张三、李四、王五、赵六。如此，我可以得知张三不仅长得可爱还高智商。这种张三对应向量[1,0,1,0,0]这种对应关系不是为了某种目的进行的，它只是一种泛泛的描述，还不能叫做Embedding。\n我们接着往下看。也把上面的5个维度扩展一下，增加“名校学历”、“勤奋”、“守时”、“诚实”、“外向”5个维度，构成10个维度进行考察评估，在面试考察中可能得到的结果是一组10维向量：</p>\n<div class=\"prism-codeblock\">\n<div class=\"code-toolbar\"><pre class=\"language-python\" id=\"10ffe77\" tabindex=\"0\"><code class=\"language-python\"><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span></code></pre><div class=\"toolbar\"><div class=\"toolbar-item\"><button aria-label=\"copy\" class=\"copy-to-clipboard-button\" data-copy-state=\"copy\" type=\"button\"><span></span></button></div></div></div>\n</div>\n<p>这个时候我们可以得出，张三是一个长得可爱，智商高，勤奋，守时，诚实的人。\n当我们考虑“招聘程序员”这个场景，那么这10个维度的描述似乎不大能看出这个人的是否符合我们的职位要求。也就是说，这10个维度取的不大合适。这时候我们可能需要替换一下考察维度。比如替换为“熟悉数据结构”、“具有大型线上项目经验”、“精通C++”、“带过团队”、“持续学习”、“名校学历”、“勤奋”、“守时”、“诚实”、“外向”\n这时我们得到一组新的向量。</p>\n<div class=\"prism-codeblock\">\n<div class=\"code-toolbar\"><pre class=\"language-python\" id=\"2d647c1\" tabindex=\"0\"><code class=\"language-python\"><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span></code></pre><div class=\"toolbar\"><div class=\"toolbar-item\"><button aria-label=\"copy\" class=\"copy-to-clipboard-button\" data-copy-state=\"copy\" type=\"button\"><span></span></button></div></div></div>\n</div>\n<p>此时我们可以看出张三对应[1,1,1,1,1,0,1,1,1,0]，得出张三是熟悉数据结构、具有大型线上项目经验、精通C++、带过团队、持续学习、非名校学历、勤奋、守时、诚实、不外向的人。\n这么看，这个人似乎很符合岗位的需要，于是决定发offer。这种面向一定目的的描述，可以被称为Embedding</p>\n<p>在这个例子中，“具有大型线上项目经验”、“精通C++”、“带过团队”、“持续学习”、“名校学历”、“勤奋”、“守时”、“诚实”、“外向” 这10个维度比“可爱，高挑，高智商，善解人意，多愁善感，名校，勤奋，守时，诚实，内向”这10个维度明显更符合我们的招聘目的。也就是说，Embedding的好坏至少有两个方面的因素：1.维度是否合适 2.维度上的描述值是否准确。</p>\n<p>在以上的例子中我们只是用0代表不属于该属性，1代表属于该属性。然而这种表示方式非常稀疏且维度很高，导致数据稀疏性和计算资源消耗的问题。但是在现实案例中我们经常会遇到数值连续变化的情况。比如在0到1之间的0.5又表示什么呢？在实际处理过程中我们通常是用该维度下的数值反应与该维度的相关程度，数值越大，表明越相关。而Embedding的目标是将这些高维稀疏的表示转换为低维稠密的向量，以便更有效地表达文本信息和模式。</p>\n<p>原理相同，我们把上面对人物的描述换成对词（可以是英文单词，也可以是中文的词）的描述，得到词向量。把离散的词数据转换成了计算机可以运算的连续数据。简而言之就是\"Embedding\"将文本中的单词或短语映射到连续向量空间中,这些向量在低维空间中表示了文本的语义信息和特征。通过Embedding，相似的单词或短语在向量空间中会更加接近，因为它们在语义上更相关。</p>\n<h2 id=\"相关链接\">相关链接 <a aria-hidden=\"true\" class=\"anchor\" href=\"#%e7%9b%b8%e5%85%b3%e9%93%be%e6%8e%a5\"><i class=\"material-icons align-middle\">link</i></a></h2><p><a data-bs-delay='{\"hide\":300,\"show\":550}' data-bs-html=\"true\" data-bs-title=\"&lt;a href='/docs/app/development_guide/database/extensions/pgvector/'&gt;&lt;p&gt;扩展&lt;/p&gt;&lt;strong&gt;pgvector: 嵌入向量和向量相似性&lt;/strong&gt;&lt;br&gt;&lt;/a&gt;\" data-bs-toggle=\"tooltip\" href=\"/docs/app/development_guide/database/extensions/pgvector/\">pgvectors文档</a></p>\n</div>\n</div>\n<div><hr class=\"doc-hr\"/>\n<div class=\"d-print-none\" id=\"doc-nav\">\n<div class=\"row flex-xl-nowrap\">\n<div class=\"col-sm-6 pt-2 doc-next\">\n<a href=\"/docs/app/development_guide/realtime/deep-dive/quotas/\">\n<div class=\"card h-100 my-1\">\n<div class=\"card-body py-2\">\n<p class=\"card-title fs-5 fw-semibold lh-base mb-0\"><i class=\"material-icons align-middle\">navigate_before</i> 实时配额</p>\n</div>\n</div>\n</a>\n</div>\n<div class=\"col-sm-6 pt-2 doc-prev\">\n<a class=\"ms-auto\" href=\"/docs/app/development_guide/hosting/static-hosting/\">\n<div class=\"card h-100 my-1 text-end\">\n<div class=\"card-body py-2\">\n<p class=\"card-title fs-5 fw-semibold lh-base mb-0\">静态托管 <i class=\"material-icons align-middle\">navigate_next</i></p>\n</div>\n</div>\n</a>\n</div>\n</div>\n</div></div>\n</div>\n</div>\n</div>\n</div>\n\n</main>",
  "markdown": "[MemFireDB备份 6](/)\n\nmenu\n\n[官网](https://memfiredb.com/)\n[论坛](https://community.memfiredb.com/)\n[登录](https://cloud.memfiredb.com/auth/login)\n\nEnable dark mode\n\nEnable light mode\n\n本页\n\n背景\n\n# 总览\n\n随着ChatGPT的爆火，人们逐渐认识到大语言模型（LLM）和生成式人工智能在多个领域具有潜力，如文稿撰写、图像生成、代码优化和信息搜索等。LLM已成为个人和企业的有力助手，引领着新的生态系统。本文将介绍Embedding相关概念以及构建由LLM驱动的专属AI对话机器人总体流程。\n\n## 背景 [*link*](#%e8%83%8c%e6%99%af)\n\nAI领域技术不断突破，越来越多的企业和个人积极探索利用大型语言模型（LLM）和生成式人工智能技术，来构建专注于特定领域的具备人工智能能力的产品。目前大型语言模型在解决通用问题方面表现出色，但由于受到训练数据和模型规模的限制，其在专业知识和时效性方面存在一定局限性。例如ChatGPT的训练的数据都是2021年及以前的，这也意味着想要咨询2021年以后的知识ChatGPT并不能给出准确的回答。\n\n在信息时代，企业的知识库更新速度不断加快。因此，对于企业而言，如果希望在大型语言模型的基础上构建特定垂直领域的人工智能产品，就需要将自身的知识库输入到大型语言模型中进行训练。但是要知道，一个大语言模型的参数动辄上百数千亿。单单本地的一点知识库放进去就是沧海一粟。很难达到想要的效果。加之对硬条件要求过高，很少企业和个人有条件能够直接“投喂”到模型里面训练。\n\n目前有两种常见的方法实现：\n\n* 微调（Fine-tuning）：通过提供新的数据集对已有模型的权重进行微调，不断更新输入以调整输出，以达到所需的结果。这适用于数据集规模不大或针对特定类型任务或风格进行训练。\n* 提示调整（Prompt-tuning）：通过调整输入提示而非修改模型权重，从而实现调整输出的目的。相较于微调，提示调整具有较低的计算成本，需要的资源和训练时间也较少，同时更加灵活。\n  但随着语言模型越来越大，Fine-tune的成本也越来越高。目前市面上已经涌现许多由大语言模型驱动的专属AI对话机器人，这些大都是通过提示调整来实现建立本地化AI知识库。\n\n## 实现原理 [*link*](#%e5%ae%9e%e7%8e%b0%e5%8e%9f%e7%90%86)\n\n本文将展示开发一款专属AI对话机器人的流程：\n\n**第一阶段：数据准备**\n\n1. 知识库信息提取和分块：从领域知识库中提取相关的文本信息，并将其分块处理。这可以包括将长文本拆分为段落或句子，提取关键词或实体等。这样可以将知识库的内容更好地组织和管理。\n2. 调用大语言模型接口生成Embedding：利用大语言模型（如OpenAI）提供的接口，将分块的文本信息输入到模型中，并生成相应的文本Embedding。这些Embedding将捕捉文本的语义和语境信息，为后续的搜索和匹配提供基础。\n3. 存储Embedding信息：将生成的文本Embedding信息、文本分块以及文本关联的metadata信息存入MemFireCloud PostgreSQL数据库中。\n\n**第二阶段：问答**\n\n1. 用户提问。\n2. 通过OpenAI提供的Embedding接口创建该问题的Embedding。通俗的说就是你发出的提问内容A，通过OpenAI的接口，返回问题内容A的一个向量，也就是我们之前说的Embedding。\n3. 因为在步骤1我们已经将我们的本地的知识库进行分片和Embedding，我们现在只需要将A的Embedding值和我们知识库分片的Embedding值进行比对，通过pgvector这个扩展，能够帮我们过滤出PostgreSQL数据库中相似度大于一定阈值的文档块.\n4. 然后将我们的提问内容A和过滤出来的文档块，作为prompt一同发送给OpenAI，并将OpenAI结果返回给用户。这样一来，用户得到的就是逻辑严谨准确率高且符合人类语法的回答。\n\n流程图如下：\n![](../../../img/ai/流程图.png)\n\n## 关于产品 [*link*](#%e5%85%b3%e4%ba%8e%e4%ba%a7%e5%93%81)\n\nMemFire Cloud提供了一个开源工具包，用于使用Postgres和pgvector开发人工智能应用程序。使用MemFire Cloud客户端库，在规模上存储、索引和查询你的Embedding。\n这个工具包含以下功能：\n\n* 使用 Postgres 与 pgvector 来实现 向量存储 和嵌入支持。\n* 提供 Python客户端 ，用于管理非结构化嵌入。\n* 提供 数据库迁移 ，用于管理结构化嵌入。\n* 支持与多个流行的 AI 供应商 (如 OpenAI 、 Hugging Face 、LangChain 等) 进行集成。\n\n## 相关概念 | Embedding [*link*](#%e7%9b%b8%e5%85%b3%e6%a6%82%e5%bf%b5--embedding)\n\n当谈到\"Embedding\"时，它通常是指将高维数据转换为低维表示的过程。在自然语言处理（NLP）和机器学习领域，“Embedding\"通常用来将单词、短语、文本或者图像数据转换为向量（也称为嵌入向量或词嵌入）。因为计算机是擅长处理数字运算的，所以将无法计算的文本数据转化为向量数据，从而便于后面的计算。\n你可能会疑问这些文本数据是如何转换成向量的，这又是如何规定的。接下来我将会为您讲解。\n\n我们描述一个人可以有很多形容词，假定我们有4个人（张三、李四、王五、赵六），给每个人都从“可爱的”、“高挑的”、“高智商的”、“善解人意的”、“多愁善感的”这5个方面进行描述。符合定义为1，不符合定义为0，那么这4个人的描述可能是：\n\n```\n[1,0,1,0,0]\n[1,1,0,0,1]\n[0,0,1,1,1]\n[1,1,1,0,0]\n```\n\n每个向量都有5个维度，每个维度都代表一个方面的描述。从左到右的依次表示为：“可爱的”、“高挑的”、“高智商的”、“善解人意的”、“多愁善感的”。向量1-4分别代表：张三、李四、王五、赵六。如此，我可以得知张三不仅长得可爱还高智商。这种张三对应向量[1,0,1,0,0]这种对应关系不是为了某种目的进行的，它只是一种泛泛的描述，还不能叫做Embedding。\n我们接着往下看。也把上面的5个维度扩展一下，增加“名校学历”、“勤奋”、“守时”、“诚实”、“外向”5个维度，构成10个维度进行考察评估，在面试考察中可能得到的结果是一组10维向量：\n\n```\n[1,0,1,0,0,0,1,1,1,0]\n[1,1,0,0,1,1,1,0,1,0]\n[0,0,1,1,1,1,1,0,0,0]\n[1,1,1,0,0,0,1,1,1,1]\n```\n\n这个时候我们可以得出，张三是一个长得可爱，智商高，勤奋，守时，诚实的人。\n当我们考虑“招聘程序员”这个场景，那么这10个维度的描述似乎不大能看出这个人的是否符合我们的职位要求。也就是说，这10个维度取的不大合适。这时候我们可能需要替换一下考察维度。比如替换为“熟悉数据结构”、“具有大型线上项目经验”、“精通C++”、“带过团队”、“持续学习”、“名校学历”、“勤奋”、“守时”、“诚实”、“外向”\n这时我们得到一组新的向量。\n\n```\n[1,1,1,1,1,0,1,1,1,0]\n[0,0,1,0,1,1,1,0,1,0]\n[1,0,0,0,1,1,1,0,0,0]\n[0,1,1,0,0,0,1,1,1,1]\n```\n\n此时我们可以看出张三对应[1,1,1,1,1,0,1,1,1,0]，得出张三是熟悉数据结构、具有大型线上项目经验、精通C++、带过团队、持续学习、非名校学历、勤奋、守时、诚实、不外向的人。\n这么看，这个人似乎很符合岗位的需要，于是决定发offer。这种面向一定目的的描述，可以被称为Embedding\n\n在这个例子中，“具有大型线上项目经验”、“精通C++”、“带过团队”、“持续学习”、“名校学历”、“勤奋”、“守时”、“诚实”、“外向” 这10个维度比“可爱，高挑，高智商，善解人意，多愁善感，名校，勤奋，守时，诚实，内向”这10个维度明显更符合我们的招聘目的。也就是说，Embedding的好坏至少有两个方面的因素：1.维度是否合适 2.维度上的描述值是否准确。\n\n在以上的例子中我们只是用0代表不属于该属性，1代表属于该属性。然而这种表示方式非常稀疏且维度很高，导致数据稀疏性和计算资源消耗的问题。但是在现实案例中我们经常会遇到数值连续变化的情况。比如在0到1之间的0.5又表示什么呢？在实际处理过程中我们通常是用该维度下的数值反应与该维度的相关程度，数值越大，表明越相关。而Embedding的目标是将这些高维稀疏的表示转换为低维稠密的向量，以便更有效地表达文本信息和模式。\n\n原理相同，我们把上面对人物的描述换成对词（可以是英文单词，也可以是中文的词）的描述，得到词向量。把离散的词数据转换成了计算机可以运算的连续数据。简而言之就是\"Embedding\"将文本中的单词或短语映射到连续向量空间中,这些向量在低维空间中表示了文本的语义信息和特征。通过Embedding，相似的单词或短语在向量空间中会更加接近，因为它们在语义上更相关。\n\n## 相关链接 [*link*](#%e7%9b%b8%e5%85%b3%e9%93%be%e6%8e%a5)\n\n[pgvectors文档](/docs/app/development_guide/database/extensions/pgvector/)\n\n---\n\n[*navigate\\_before* 实时配额](/docs/app/development_guide/realtime/deep-dive/quotas/)\n\n[静态托管 *navigate\\_next*](/docs/app/development_guide/hosting/static-hosting/)"
}